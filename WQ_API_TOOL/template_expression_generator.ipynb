{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wq_api import *\n",
    "\n",
    "session = sign_in(username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数,alpha表达式见后\n",
    "setting = {\n",
    "    'region': 'GLB', \n",
    "    'universe': 'MINVOL1M', \n",
    "    'delay': 1,\n",
    "    'decay': 4,\n",
    "    'neutralization':'SUBINDUSTRY'} \n",
    "\n",
    "dataset_id_ls = [{'id':'analyst9','backfill':False},\n",
    "                 {'id':'analyst69','backfill':False},\n",
    "                 {'id':'analyst44','backfill':False},\n",
    "                 ]\n",
    "\n",
    "# 只要vector还是只要matrix,目前只支持处理一种数据类型\n",
    "vec_only = False\n",
    "\n",
    "dir_path = './727'\n",
    "\n",
    "# 仅作为记录，并不作为操作，alpha表达式仍需在之后修改\n",
    "template = 'piece_1 = group_mean(vec_stddev({}) , 1 , subindustry) - vec_stddev({});ts_mean(piece_1, 60)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "record_file = 'record.csv'\n",
    "\n",
    "rows = []\n",
    "for item in dataset_id_ls:\n",
    "    row = {'template':template, 'vec_only':vec_only, 'dir_path':dir_path, **item, **setting}\n",
    "    rows.append(row)\n",
    "combined_df = pd.DataFrame(rows)\n",
    "\n",
    "if os.path.exists(record_file):\n",
    "    existing_df = pd.read_csv(record_file)\n",
    "    combined_df = pd.concat([existing_df, combined_df], ignore_index=True)\n",
    "else:\n",
    "    combined_df.to_csv(record_file, index=False)\n",
    "\n",
    "combined_df.to_csv(record_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is restored in {index}_refine_1.csv, where index is generated by order\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    to_path = f'{dir_path}/{index}_data_1.csv'\n",
    "    if not os.path.exists(to_path):\n",
    "        break\n",
    "    index += 1\n",
    "\n",
    "print(f'Next available file path: {to_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for dataset in dataset_id_ls:\n",
    "    dataset_id = dataset['id']\n",
    "    backfill = dataset['backfill']\n",
    "    \n",
    "    datafields_df = get_datafields(session, dataset_id=dataset_id, region=setting['region'], universe=setting['universe'], delay=setting['delay'])\n",
    "    if vec_only:\n",
    "        datafields_df = datafields_df[datafields_df['type'] == \"VECTOR\"][['id','dataset']]\n",
    "    else:\n",
    "        datafields_df = datafields_df[datafields_df['type'] == \"MATRIX\"][['id','dataset']]\n",
    "\n",
    "    datafields_df['backfill'] = backfill\n",
    "    \n",
    "    df = pd.concat([df, datafields_df])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if(row['backfill']==True):\n",
    "        df.loc[index, 'regular'] = \"piece_1 = group_mean(vec_stddev({}) , 1 , subindustry) - vec_stddev({});ts_mean(piece_1, 60)\" \\\n",
    "                          .format(row['id'],row['id'])\n",
    "    else:\n",
    "        df.loc[index, 'regular'] = \"piece_1 = group_mean(vec_stddev({}) , 1 , subindustry) - vec_stddev({});ts_mean(piece_1, 60)\" \\\n",
    "                          .format(row['id'],row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test alpha list\n",
    "alpha_list=[]\n",
    "for index, row in df.iterrows():\n",
    "    alpha_list.append(\n",
    "        {\n",
    "            'type': 'REGULAR',\n",
    "            'settings': {\n",
    "                'instrumentType': 'EQUITY',\n",
    "                'region': 'GLB',\n",
    "                'universe': setting['universe'],\n",
    "                'delay': setting['delay'],\n",
    "                'decay': setting['decay'],\n",
    "                'neutralization': setting['neutralization'],\n",
    "                'truncation': 0.08,\n",
    "                'pasteurization': 'ON',\n",
    "                'unitHandling': 'VERIFY',\n",
    "                'nanHandling': 'ON',\n",
    "                'language': 'FASTEXPR',\n",
    "                'visualization': False,\n",
    "            },\n",
    "            'regular': row['regular']\n",
    "        })\n",
    "alpha_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(alpha_list)\n",
    "settings_df = alpha_df['settings'].apply(pd.Series)\n",
    "alpha_df = pd.concat([alpha_df.drop(columns=['settings']), settings_df], axis=1)\n",
    "alpha_df.set_index(['regular'],inplace=True)\n",
    "alpha_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['regular'],inplace=True)\n",
    "# 将展开的 settings 列与其他列合并\n",
    "df = pd.concat([df, alpha_df], axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(to_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
