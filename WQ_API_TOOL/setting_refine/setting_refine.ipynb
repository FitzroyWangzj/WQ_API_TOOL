{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wq_api import *\n",
    "\n",
    "session = sign_in(username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is restored in {index}_refine_1.csv, where index is generated by order\n",
    "import os\n",
    "\n",
    "dir_path = './refine_data'\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    to_path = f'{dir_path}/{index}_refine_1.csv'\n",
    "    if not os.path.exists(to_path):\n",
    "        break\n",
    "    index += 1\n",
    "\n",
    "print(f'Next available file path: {to_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = {\n",
    "    'universe':['TOP3000', 'MINVOL1M'],\n",
    "    'decay':[4,6,10,20,25,30,60,120,252],\n",
    "    'neutralization':['MARKET','INDUSTRY','SUBINDUSTRY','SECTOR','COUNTRY']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make alpha template\n",
    "alphas = []\n",
    "\n",
    "alpha = \"market_return = group_mean(returns,1,market);fear = ts_mean(abs(returns - market_return)/(abs(returns)+abs(market_return)),20);vhat = ts_regression(volume,ts_mean(anl15_s_12_m_mean,60),120);ehat = ts_regression(returns-market_return,vhat,120);alpha = group_neutralize(-ehat*rank(fear),bucket(rank(cap),range='0,1,0.1'));final = group_zscore(alpha,densify(country));is_nan(final)?0.0001:final\"\n",
    "alphas.append(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test alpha list\n",
    "priority_alpha_list=[]\n",
    "priority_alpha_list = [\n",
    "    {\n",
    "        'type': 'REGULAR',\n",
    "        'settings': {\n",
    "            'instrumentType': 'EQUITY',\n",
    "            'region': 'GLB',\n",
    "            'universe': universe,\n",
    "            'delay': 1,\n",
    "            'decay': decay,\n",
    "            'neutralization': neutralization,\n",
    "            'truncation': 0.08,\n",
    "            'pasteurization': 'ON',\n",
    "            'unitHandling': 'VERIFY',\n",
    "            'nanHandling': 'ON',\n",
    "            'language': 'FASTEXPR',\n",
    "            'visualization': False,\n",
    "        },\n",
    "        'regular': alpha\n",
    "    }\n",
    "    for alpha in alphas\n",
    "    for universe in setting['universe']\n",
    "    for decay in setting['decay']\n",
    "    for neutralization in setting['neutralization']\n",
    "]\n",
    "    # simulation_response = session.post('https://api.worldquantbrain.com/simulations', json=simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 将 priority_alpha_list 转换为 DataFrame\n",
    "priority_alpha_df = pd.DataFrame(priority_alpha_list)\n",
    "\n",
    "# 将 settings 列中的字典展开为单独的列\n",
    "settings_df = priority_alpha_df['settings'].apply(pd.Series)\n",
    "\n",
    "# 将展开的 settings 列与其他列合并\n",
    "priority_alpha_df = pd.concat([priority_alpha_df.drop(columns=['settings']), settings_df], axis=1)\n",
    "\n",
    "print(priority_alpha_df)\n",
    "\n",
    "priority_alpha_df.to_csv(to_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
